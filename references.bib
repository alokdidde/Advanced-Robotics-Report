@misc{kerbl20233dgaussiansplattingrealtime,
  title         = {3D Gaussian Splatting for Real-Time Radiance Field Rendering},
  author        = {Bernhard Kerbl and Georgios Kopanas and Thomas Leimkühler and George Drettakis},
  year          = {2023},
  eprint        = {2308.04079},
  archiveprefix = {arXiv},
  primaryclass  = {cs.GR},
  url           = {https://arxiv.org/abs/2308.04079}
}

@misc{chen2024splatnavsaferealtimerobot,
  title         = {Splat-Nav: Safe Real-Time Robot Navigation in Gaussian Splatting Maps},
  author        = {Timothy Chen and Ola Shorinwa and Joseph Bruno and Javier Yu and Weijia Zeng and Keiko Nagami and Philip Dames and Mac Schwager},
  year          = {2024},
  eprint        = {2403.02751},
  archiveprefix = {arXiv},
  primaryclass  = {cs.RO},
  url           = {https://arxiv.org/abs/2403.02751}
}


@misc{guo2024semanticgaussiansopenvocabularyscene,
  title         = {Semantic Gaussians: Open-Vocabulary Scene Understanding with 3D Gaussian Splatting},
  author        = {Jun Guo and Xiaojian Ma and Yue Fan and Huaping Liu and Qing Li},
  year          = {2024},
  eprint        = {2403.15624},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV},
  url           = {https://arxiv.org/abs/2403.15624}
}

@misc{liao2024clipgsclipinformedgaussiansplatting,
  title         = {CLIP-GS: CLIP-Informed Gaussian Splatting for Real-time and View-consistent 3D Semantic Understanding},
  author        = {Guibiao Liao and Jiankun Li and Zhenyu Bao and Xiaoqing Ye and Jingdong Wang and Qing Li and Kanglin Liu},
  year          = {2024},
  eprint        = {2404.14249},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV},
  url           = {https://arxiv.org/abs/2404.14249}
}

@Article{KKLD23,
  author       = "Kerbl, Bernhard and Kopanas, Georgios and Leimk{\"u}hler, Thomas and Drettakis, George",
  title        = "3D Gaussian Splatting for Real-Time Radiance Field Rendering",
  journal      = "ACM Transactions on Graphics (SIGGRAPH Conference Proceedings)",
  number       = "4",
  volume       = "42",
  month        = "July",
  year         = "2023",
  url          = "http://www-sop.inria.fr/reves/Basilic/2023/KKLD23"
}

@misc{douze2024faisslibrary,
      title={The Faiss library}, 
      author={Matthijs Douze and Alexandr Guzhva and Chengqi Deng and Jeff Johnson and Gergely Szilvasy and Pierre-Emmanuel Mazaré and Maria Lomeli and Lucas Hosseini and Hervé Jégou},
      year={2024},
      eprint={2401.08281},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2401.08281}, 
}

@misc{che2024enhancingmultimodalunderstandingclipbased,
      title={Enhancing Multimodal Understanding with CLIP-Based Image-to-Text Transformation}, 
      author={Chang Che and Qunwei Lin and Xinyu Zhao and Jiaxin Huang and Liqiang Yu},
      year={2024},
      eprint={2401.06167},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2401.06167}, 
}

@misc{bortolon20246dgs6dposeestimation,
      title={6DGS: 6D Pose Estimation from a Single Image and a 3D Gaussian Splatting Model}, 
      author={Matteo Bortolon and Theodore Tsesmelis and Stuart James and Fabio Poiesi and Alessio Del Bue},
      year={2024},
      eprint={2407.15484},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2407.15484}, 
}

@article{DURAKLI2022101540,
title = {A new approach based on Bezier curves to solve path planning problems for mobile robots},
journal = {Journal of Computational Science},
volume = {58},
pages = {101540},
year = {2022},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2021.101540},
url = {https://www.sciencedirect.com/science/article/pii/S1877750321001988},
author = {Zafer Duraklı and Vasif Nabiyev},
keywords = {Path planning, Optimum path, Bezier curve, Prune strategy, Smoothing spikes},
abstract = {Path planning algorithms are used in known environments to find the shortest, smooth and optimal way without collision from the starting point to the target point. However, excessive nodes and pointed spiking points that occur during this path planning process pose problems. Bezier curves offer highly effective possibilities for path forming problems. In this article, a new approach based on Bezier curves is proposed for solving such problems. First, grid maps are used to model the environment Second, a path is found between the start and endpoints using traditional algorithms. Third, the excess knots are discarded by pruning based on Bezier curves. Finally, the spikes are smoothed using Bezier curves to ensure smoothness and continuity. Looking at the results from the proposed approach, it has proven that its effectiveness in obtaining an optimum path between the starting and target points in known environments.}
}

@misc{ravi2024sam,
    title={SAM 2: Segment Anything in Images and Videos},
    author={Nikhila Ravi and Valentin Gabeur and Yuan-Ting Hu and Ronghang Hu and Chaitanya Ryali and Tengyu Ma and Haitham Khedr and Roman Rädle and Chloe Rolland and Laura Gustafson and Eric Mintun and Junting Pan and Kalyan Vasudev Alwala and Nicolas Carion and Chao-Yuan Wu and Ross Girshick and Piotr Dollár and Christoph Feichtenhofer},
    year={2024},
    eprint={2408.00714},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@INPROCEEDINGS{10353343,
  author={Thotad, Puneeth N. and Kallur, Shanta and Nandeppanavar, Anupama},
  booktitle={2023 4th IEEE Global Conference for Advancement in Technology (GCAT)}, 
  title={An Efficient Model for Plant Disease Detection in Agriculture Using Deep Learning Approaches}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  keywords={Deep learning;Plant diseases;Visualization;Image color analysis;Plants (biology);Transfer learning;Neural networks;Plant disease;Machine Learning;Deep Learning;Convolutional neural networks},
  doi={10.1109/GCAT59970.2023.10353343}}

  @misc{J2019,
  author = {Arun Pandian J and Geetharamani Gopal},
  title = {Data for: Identification of Plant Leaf Diseases Using a 9-layer Deep Convolutional Neural Network},
  year = {2019},
  publisher = {Mendeley Data},
  version = {V1},
  doi = {10.17632/tywbtsjrjv.1},
  url = {https://doi.org/10.17632/tywbtsjrjv.1}
}

@ARTICLE{10.3389/fpls.2016.01419,

AUTHOR={Mohanty, Sharada P.  and Hughes, David P.  and Salathé, Marcel },

TITLE={Using Deep Learning for Image-Based Plant Disease Detection},

JOURNAL={Frontiers in Plant Science},

VOLUME={7},

YEAR={2016},

URL={https://www.frontiersin.org/journals/plant-science/articles/10.3389/fpls.2016.01419},

DOI={10.3389/fpls.2016.01419},

ISSN={1664-462X},

ABSTRACT={<p>Crop diseases are a major threat to food security, but their rapid identification remains difficult in many parts of the world due to the lack of the necessary infrastructure. The combination of increasing global smartphone penetration and recent advances in computer vision made possible by deep learning has paved the way for smartphone-assisted disease diagnosis. Using a public dataset of 54,306 images of diseased and healthy plant leaves collected under controlled conditions, we train a deep convolutional neural network to identify 14 crop species and 26 diseases (or absence thereof). The trained model achieves an accuracy of 99.35% on a held-out test set, demonstrating the feasibility of this approach. Overall, the approach of training deep learning models on increasingly large and publicly available image datasets presents a clear path toward smartphone-assisted crop disease diagnosis on a massive global scale.</p>}}

@misc{oshea2015introductionconvolutionalneuralnetworks,
      title={An Introduction to Convolutional Neural Networks}, 
      author={Keiron O'Shea and Ryan Nash},
      year={2015},
      eprint={1511.08458},
      archivePrefix={arXiv},
      primaryClass={cs.NE},
      url={https://arxiv.org/abs/1511.08458}, 
}

@misc{yim2017enhancingperformanceconvolutionalneural,
      title={Enhancing the Performance of Convolutional Neural Networks on Quality Degraded Datasets}, 
      author={Jonghwa Yim and Kyung-Ah Sohn},
      year={2017},
      eprint={1710.06805},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1710.06805}, 
}

@misc{radenović2018finetuningcnnimageretrieval,
      title={Fine-tuning CNN Image Retrieval with No Human Annotation}, 
      author={Filip Radenović and Giorgos Tolias and Ondřej Chum},
      year={2018},
      eprint={1711.02512},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1711.02512}, 
}

@misc{kim2024openvlaopensourcevisionlanguageactionmodel,
      title={OpenVLA: An Open-Source Vision-Language-Action Model}, 
      author={Moo Jin Kim and Karl Pertsch and Siddharth Karamcheti and Ted Xiao and Ashwin Balakrishna and Suraj Nair and Rafael Rafailov and Ethan Foster and Grace Lam and Pannag Sanketi and Quan Vuong and Thomas Kollar and Benjamin Burchfiel and Russ Tedrake and Dorsa Sadigh and Sergey Levine and Percy Liang and Chelsea Finn},
      year={2024},
      eprint={2406.09246},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2406.09246}, 
}

@misc{touvron2023llamaopenefficientfoundation,
      title={LLaMA: Open and Efficient Foundation Language Models}, 
      author={Hugo Touvron and Thibaut Lavril and Gautier Izacard and Xavier Martinet and Marie-Anne Lachaux and Timothée Lacroix and Baptiste Rozière and Naman Goyal and Eric Hambro and Faisal Azhar and Aurelien Rodriguez and Armand Joulin and Edouard Grave and Guillaume Lample},
      year={2023},
      eprint={2302.13971},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2302.13971}, 
}

@misc{sutskever2014sequencesequencelearningneural,
      title={Sequence to Sequence Learning with Neural Networks}, 
      author={Ilya Sutskever and Oriol Vinyals and Quoc V. Le},
      year={2014},
      eprint={1409.3215},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1409.3215}, 
}

@misc{müller2021openbotturningsmartphonesrobots,
      title={OpenBot: Turning Smartphones into Robots}, 
      author={Matthias Müller and Vladlen Koltun},
      year={2021},
      eprint={2008.10631},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2008.10631}, 
}

@misc{azghadi2024preciseroboticweedspotspraying,
      title={Precise Robotic Weed Spot-Spraying for Reduced Herbicide Usage and Improved Environmental Outcomes -- A Real-World Case Study}, 
      author={Mostafa Rahimi Azghadi and Alex Olsen and Jake Wood and Alzayat Saleh and Brendan Calvert and Terry Granshaw and Emilie Fillols and Bronson Philippa},
      year={2024},
      eprint={2401.13931},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2401.13931}, 
}

@misc{duckett2018agriculturalroboticsfuturerobotic,
      title={Agricultural Robotics: The Future of Robotic Agriculture}, 
      author={Tom Duckett and Simon Pearson and Simon Blackmore and Bruce Grieve and Wen-Hua Chen and Grzegorz Cielniak and Jason Cleaversmith and Jian Dai and Steve Davis and Charles Fox and Pål From and Ioannis Georgilas and Richie Gill and Iain Gould and Marc Hanheide and Alan Hunter and Fumiya Iida and Lyudmila Mihalyova and Samia Nefti-Meziani and Gerhard Neumann and Paolo Paoletti and Tony Pridmore and Dave Ross and Melvyn Smith and Martin Stoelen and Mark Swainson and Sam Wane and Peter Wilson and Isobel Wright and Guang-Zhong Yang},
      year={2018},
      eprint={1806.06762},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/1806.06762}, 
}

@misc{sitokonstantinou2024causalmachinelearningsustainable,
      title={Causal machine learning for sustainable agroecosystems}, 
      author={Vasileios Sitokonstantinou and Emiliano Díaz Salas Porras and Jordi Cerdà Bautista and Maria Piles and Ioannis Athanasiadis and Hannah Kerner and Giulia Martini and Lily-belle Sweet and Ilias Tsoumas and Jakob Zscheischler and Gustau Camps-Valls},
      year={2024},
      eprint={2408.13155},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2408.13155}, 
}

@misc{zhang2024visuallocalization3dmaps,
      title={Visual Localization in 3D Maps: Comparing Point Cloud, Mesh, and NeRF Representations}, 
      author={Lintong Zhang and Yifu Tao and Jiarong Lin and Fu Zhang and Maurice Fallon},
      year={2024},
      eprint={2408.11966},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2408.11966}, 
}

@inproceedings{Tancik_2023, series={SIGGRAPH ’23},
   title={Nerfstudio: A Modular Framework for Neural Radiance Field Development},
   url={http://dx.doi.org/10.1145/3588432.3591516},
   DOI={10.1145/3588432.3591516},
   booktitle={Special Interest Group on Computer Graphics and Interactive Techniques Conference Conference Proceedings},
   publisher={ACM},
   author={Tancik, Matthew and Weber, Ethan and Ng, Evonne and Li, Ruilong and Yi, Brent and Wang, Terrance and Kristoffersen, Alexander and Austin, Jake and Salahi, Kamyar and Ahuja, Abhik and Mcallister, David and Kerr, Justin and Kanazawa, Angjoo},
   year={2023},
   month=jul, collection={SIGGRAPH ’23} }

@article{Elsheikh2023,
  author    = {Mogeeb A. Elsheikh},
  title     = {Design of a special rigid wheel for traversing loose soil},
  journal   = {Scientific Reports},
  year      = {2023},
  volume    = {13},
  number    = {1},
  pages     = {171},
  doi       = {10.1038/s41598-022-27312-6},
  url       = {https://doi.org/10.1038/s41598-022-27312-6},
  abstract  = {Wheels play an important role in mobile robotics, wheelchairs and vehicles and represent an ideal solution for traversing rigid ground due to higher efficiency. Through traversing loose soil, the rigid wheels lose traction because of sinking and higher slip ratios. Therefore, the study suggests a new rigid wheel with a distinguished perimeter to increase mobility demands to overcome the previous inevitable concerns and clarifies its full detailed design. The lateral undulation locomotion of snakes inspired the author to introduce a new simple and affordable wheel design. The optimum values of the limbless creature movement on the sand are reflected in the geometrical parameters of the wheel, amplitude to wavelength ratio. In addition, the experimental work assessed the traveling performance of the fabricated wheel on the rigid ground and the sandy soil. The attained net traction and slip ratios approach the values of more complicated, expensive and heavier wheels that were used in farming and planetary exploration. Consequently, the wheel enables the wheeled locomotive to do missions on sandy soil with no trouble.},
  issn      = {2045-2322},
}

@misc{cieslak2024generatingdiverseagriculturaldata,
      title={Generating Diverse Agricultural Data for Vision-Based Farming Applications}, 
      author={Mikolaj Cieslak and Umabharathi Govindarajan and Alejandro Garcia and Anuradha Chandrashekar and Torsten Hädrich and Aleksander Mendoza-Drosik and Dominik L. Michels and Sören Pirk and Chia-Chun Fu and Wojciech Pałubicki},
      year={2024},
      eprint={2403.18351},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2403.18351}, 
}
